import pandas as pd
import numpy as np
import time
from sklearn.ensemble import RandomForestClassifier
from skmultilearn.problem_transform import LabelPowerset
from sklearn.metrics import (
    accuracy_score, hamming_loss, f1_score,
    precision_score, recall_score, jaccard_score
)
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import KFold

# ▶️ Load the dataset
file_path = r"C:\Users\HP\Dropbox\PHD\level 2\SWE620\project\Fdroid\variable\var_multi_label_balanced_ml_ros.csv"
df = pd.read_csv(file_path)

# ▶️ Define the identifier columns (to drop and restore later)
identifier_columns = ['className', 'fullMethodName', 'variableName']

# ▶️ Define label columns
label_columns = [
    'Rename Variable',
    'Rename Parameter',
    'Parameterize Variable',
    'Replace Variable With Attribute',
    'Inline Variable',
    'Extract Variable'
]

# ▶️ Store identifiers separately to merge back later if needed
identifiers = df[identifier_columns]

# ▶️ Drop identifiers + label columns from features
X = df.drop(columns=label_columns + identifier_columns).copy()
y = df[label_columns].copy()

# ▶️ Ensure no NaN or Inf values (just in case)
X = X.fillna(0)
X.replace([np.inf, -np.inf], 0, inplace=True)

# ▶️ Scale features (optional)
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# ▶️ 10-Fold Cross Validation
kf = KFold(n_splits=10, shuffle=True, random_state=42)

# ▶️ Metrics storage
accuracy_scores = []
jaccard_accuracies = []
hamming_losses = []
f1_macros = []
f1_micros = []
precision_macros = []
precision_micros = []
recall_macros = []
recall_micros = []

# ▶️ Start overall timing
start_time = time.time()

fold = 1
for train_index, test_index in kf.split(X_scaled):
    print(f"\nTraining Fold {fold}...")

    # ▶️ Per fold timing
    fold_start_time = time.time()

    X_train, X_test = X_scaled[train_index], X_scaled[test_index]
    y_train, y_test = y.iloc[train_index], y.iloc[test_index]

    # ▶️ RandomForest Classifier with specific parameters
    rf_classifier = RandomForestClassifier(
        n_estimators=500,
        max_depth=50,
        criterion='entropy',
        class_weight=None,
        random_state=42,
        n_jobs=-1,
        
    )

    # ▶️ Wrap RF in Label Powerset transformation
    lp_classifier = LabelPowerset(classifier=rf_classifier)

    # ▶️ Train
    lp_classifier.fit(X_train, y_train)

    # ▶️ Predict
    y_pred = lp_classifier.predict(X_test)
    y_pred = y_pred.toarray()  # Convert sparse matrix to dense

    # ▶️ Evaluation Metrics
    acc = accuracy_score(y_test, y_pred)
    jaccard_acc = jaccard_score(y_test, y_pred, average='samples')
    ham_loss = hamming_loss(y_test, y_pred)
    f1_macro = f1_score(y_test, y_pred, average='macro', zero_division=0)
    f1_micro = f1_score(y_test, y_pred, average='micro', zero_division=0)
    precision_macro = precision_score(y_test, y_pred, average='macro', zero_division=0)
    precision_micro = precision_score(y_test, y_pred, average='micro', zero_division=0)
    recall_macro = recall_score(y_test, y_pred, average='macro', zero_division=0)
    recall_micro = recall_score(y_test, y_pred, average='micro', zero_division=0)

    # ▶️ Store metrics
    accuracy_scores.append(acc)
    jaccard_accuracies.append(jaccard_acc)
    hamming_losses.append(ham_loss)
    f1_macros.append(f1_macro)
    f1_micros.append(f1_micro)
    precision_macros.append(precision_macro)
    precision_micros.append(precision_micro)
    recall_macros.append(recall_macro)
    recall_micros.append(recall_micro)

    # ▶️ Print per fold results
    fold_time = (time.time() - fold_start_time)
    print(f"Fold {fold} Completed in {fold_time:.2f} seconds.")
    print(f"Subset Accuracy     : {acc:.4f}")
    print(f"Jaccard Accuracy    : {jaccard_acc:.4f}")
    print(f"Hamming Loss        : {ham_loss:.4f}")
    print(f"F1 Macro            : {f1_macro:.4f}")
    print(f"F1 Micro            : {f1_micro:.4f}")
    print(f"Precision Macro     : {precision_macro:.4f}")
    print(f"Precision Micro     : {precision_micro:.4f}")
    print(f"Recall Macro        : {recall_macro:.4f}")
    print(f"Recall Micro        : {recall_micro:.4f}")

    fold += 1

# ▶️ End overall timing
end_time = time.time()
training_duration = (end_time - start_time) / 60  # minutes

# ▶️ Cross-Validation Results Summary
print("\n--- 10-Fold Cross-Validation Results (Label Powerset + RandomForest) ---")
print(f"Subset Accuracy    : {np.mean(accuracy_scores):.4f} (+/- {np.std(accuracy_scores):.4f})")
print(f"Jaccard Accuracy   : {np.mean(jaccard_accuracies):.4f} (+/- {np.std(jaccard_accuracies):.4f})")
print(f"Hamming Loss       : {np.mean(hamming_losses):.4f} (+/- {np.std(hamming_losses):.4f})")
print(f"F1 Macro           : {np.mean(f1_macros):.4f} (+/- {np.std(f1_macros):.4f})")
print(f"F1 Micro           : {np.mean(f1_micros):.4f} (+/- {np.std(f1_micros):.4f})")
print(f"Precision Macro    : {np.mean(precision_macros):.4f} (+/- {np.std(precision_macros):.4f})")
print(f"Precision Micro    : {np.mean(precision_micros):.4f} (+/- {np.std(precision_micros):.4f})")
print(f"Recall Macro       : {np.mean(recall_macros):.4f} (+/- {np.std(recall_macros):.4f})")
print(f"Recall Micro       : {np.mean(recall_micros):.4f} (+/- {np.std(recall_micros):.4f})")
print(f"\nTotal Training Time: {training_duration:.2f} minutes")

# ▶️ (Optional) Merge identifiers back if you want to join predictions to the original data
# merged_results = pd.concat([identifiers, y, pd.DataFrame(y_pred, columns=[f'Pred_{col}' for col in label_columns])], axis=1)
# print(merged_results.head())
