import pandas as pd
import numpy as np
import time
from sklearn.tree import DecisionTreeClassifier
from sklearn.multioutput import ClassifierChain
from sklearn.metrics import (
    accuracy_score,
    hamming_loss,
    f1_score,
    precision_score,
    recall_score,
    jaccard_score
)
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import KFold
import matplotlib.pyplot as plt

# === Step 1: Load the dataset ===
file_path = r"C:\Users\HP\Dropbox\PHD\level 2\SWE620\project\Fdroid\variable\var_multi_label_balanced_ml_ros.csv"
df = pd.read_csv(file_path)

# === Step 2: Define identifiers and label columns ===
identifier_columns = ['className', 'fullMethodName', 'variableName']
label_columns = [
    'Rename Variable',
    'Rename Parameter',
    'Parameterize Variable',
    'Replace Variable With Attribute',
    'Inline Variable',
    'Extract Variable'
]

# === Step 3: Prepare features and labels ===
X = df.drop(columns=label_columns + identifier_columns)
y = df[label_columns]

# === Optional Scaling ===
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# === Step 4: 10-Fold Cross-Validation ===
kf = KFold(n_splits=10, shuffle=True, random_state=42)

# === Decision Tree Parameters ===
dt_classifier_params = dict(
    max_depth=50,
    criterion='entropy',
    splitter='best',
    min_samples_split=2,
    min_samples_leaf=1,
    min_impurity_decrease=0.0,
    random_state=42
)

# === Metric storage ===
accuracy_scores = []
hamming_losses = []
jaccard_accuracies = []
f1_macros = []
f1_micros = []
precision_macros = []
precision_micros = []
recall_macros = []
recall_micros = []

# === Start timing ===
start_time = time.time()

# === Cross-validation loop ===
fold = 1
for train_index, test_index in kf.split(X_scaled):
    print(f"\n=== Fold {fold} ===")

    X_train, X_test = X_scaled[train_index], X_scaled[test_index]
    y_train, y_test = y.iloc[train_index], y.iloc[test_index]

    # === Create Classifier Chain with Decision Tree ===
    base_dt = DecisionTreeClassifier(**dt_classifier_params)
    cc_classifier = ClassifierChain(base_dt)

    # === Train ===
    cc_classifier.fit(X_train, y_train)

    # === Predict ===
    y_pred = cc_classifier.predict(X_test)

    # Convert to dense if sparse matrix returned
    if hasattr(y_pred, "toarray"):
        y_pred = y_pred.toarray()

    # === Metrics Calculation ===
    acc = accuracy_score(y_test, y_pred)
    ham_loss = hamming_loss(y_test, y_pred)
    jaccard_acc = jaccard_score(y_test, y_pred, average='samples', zero_division=0)  # Mean Jaccard Accuracy
    f1_macro = f1_score(y_test, y_pred, average='macro', zero_division=0)
    f1_micro = f1_score(y_test, y_pred, average='micro', zero_division=0)
    precision_macro = precision_score(y_test, y_pred, average='macro', zero_division=0)
    precision_micro = precision_score(y_test, y_pred, average='micro', zero_division=0)
    recall_macro = recall_score(y_test, y_pred, average='macro', zero_division=0)
    recall_micro = recall_score(y_test, y_pred, average='micro', zero_division=0)

    # === Store metrics ===
    accuracy_scores.append(acc)
    hamming_losses.append(ham_loss)
    jaccard_accuracies.append(jaccard_acc)
    f1_macros.append(f1_macro)
    f1_micros.append(f1_micro)
    precision_macros.append(precision_macro)
    precision_micros.append(precision_micro)
    recall_macros.append(recall_macro)
    recall_micros.append(recall_micro)

    print(f"Fold {fold} Completed.")
    fold += 1

# === End timing ===
end_time = time.time()
training_duration = (end_time - start_time) / 60  # minutes

# === Cross-Validation Results ===
print("\n===============================================")
print("10-Fold Cross-Validation Results (CC + DT)")
print("===============================================\n")
print(f"Subset Accuracy    : {np.mean(accuracy_scores):.4f} ± {np.std(accuracy_scores):.4f}")
print(f"Jaccard Accuracy   : {np.mean(jaccard_accuracies):.4f} ± {np.std(jaccard_accuracies):.4f}")
print(f"Hamming Loss       : {np.mean(hamming_losses):.4f} ± {np.std(hamming_losses):.4f}")
print(f"F1 Macro           : {np.mean(f1_macros):.4f} ± {np.std(f1_macros):.4f}")
print(f"F1 Micro           : {np.mean(f1_micros):.4f} ± {np.std(f1_micros):.4f}")
print(f"Precision Macro    : {np.mean(precision_macros):.4f} ± {np.std(precision_macros):.4f}")
print(f"Precision Micro    : {np.mean(precision_micros):.4f} ± {np.std(precision_micros):.4f}")
print(f"Recall Macro       : {np.mean(recall_macros):.4f} ± {np.std(recall_macros):.4f}")
print(f"Recall Micro       : {np.mean(recall_micros):.4f} ± {np.std(recall_micros):.4f}")
print(f"\nTotal Training Time: {training_duration:.2f} minutes")

# === Optional: Train on all data and plot label distribution in predictions ===
final_dt = DecisionTreeClassifier(**dt_classifier_params)
final_cc_classifier = ClassifierChain(final_dt)

final_cc_classifier.fit(X_scaled, y)
y_pred_all = final_cc_classifier.predict(X_scaled)

if hasattr(y_pred_all, "toarray"):
    y_pred_all = y_pred_all.toarray()

# === Label distribution plot ===
pred_label_counts = pd.DataFrame(y_pred_all, columns=label_columns).sum()

plt.figure(figsize=(10, 6))
plt.bar(pred_label_counts.index, pred_label_counts.values, color='teal')
plt.title("Label Distribution in Predictions (CC + DT, Full Data)")
plt.xlabel("Refactoring Labels")
plt.ylabel("Frequency")
plt.xticks(rotation=45)
plt.grid(axis='y')
plt.show()
